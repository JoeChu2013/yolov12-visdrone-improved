# YOLOv12 with P2 Head + BiFPN + CA + SIoU
nc: 80 # number of classes
scales: # model compound scaling constants
  # [depth, width, max_channels]
  n: [0.50, 0.25, 1024]
  s: [0.50, 0.50, 1024]
  m: [0.50, 1.00, 512]
  l: [1.00, 1.00, 512]
  x: [1.00, 1.50, 512]

# YOLO12-turbo backbone
backbone:
  # [from, repeats, module, args]
  - [-1, 1, Conv,  [64, 3, 2]] # 0
  - [-1, 1, Conv,  [128, 3, 2, 1, 2]] # 1
  - [-1, 2, C3k2,  [256, False, 0.25]] # 2 (P2) -> Keep for P2 Head
  - [-1, 1, Conv,  [256, 3, 2, 1, 4]] # 3 (Downsample to P3)
  - [-1, 2, C3k2,  [512, False, 0.25]] # 4 (P3 features)
  - [-1, 1, CoordAtt, [512]] # 5 (CA on P3)
  - [-1, 1, Conv,  [512, 3, 2]] # 6 (Downsample to P4)
  - [-1, 4, A2C2f, [512, True, 4]] # 7 (P4 features)
  - [-1, 1, CoordAtt, [512]] # 8 (CA on P4)
  - [-1, 1, Conv,  [1024, 3, 2]] # 9 (Downsample to P5)
  - [-1, 4, A2C2f, [1024, True, 1]] # 10 (P5 features)
  - [-1, 1, CoordAtt, [1024]] # 11 (CA on P5)

# YOLO12-turbo head with BiFPN structure (Weighted Fusion)
head:
  # Top-down P5 -> P4
  - [-1, 1, Conv, [512, 1, 1]] # 12 Reduce P5 to 512
  - [-1, 1, nn.Upsample, [None, 2, "nearest"]] # 13
  - [[-1, 8], 1, BiFPN_Add2, [512, 512]] # 14 Fuse P5_up + P4 (Layer 8)
  - [-1, 2, A2C2f, [512, False, -1]] # 15 (P4_td)

  # Top-down P4 -> P3
  - [-1, 1, nn.Upsample, [None, 2, "nearest"]] # 16 (No reduction needed, already 512)
  - [[-1, 5], 1, BiFPN_Add2, [512, 512]] # 17 Fuse P4_up + P3 (Layer 5)
  - [-1, 2, A2C2f, [512, False, -1]] # 18 (P3_out)

  # Top-down P3 -> P2 (NEW for Small Targets)
  # P3_out is 512 channels (from Layer 18)
  # P2 (Layer 2) is 256 channels
  - [-1, 1, Conv, [256, 1, 1]] # 19 Reduce P3(512) -> 256
  - [-1, 1, nn.Upsample, [None, 2, "nearest"]] # 20
  - [[-1, 2], 1, BiFPN_Add2, [256, 256]] # 21 Fuse P3_up + P2 (Layer 2)
  - [-1, 2, C3k2, [256, False, 0.25]] # 22 (P2_out)

  # Bottom-up P2 -> P3
  - [-1, 1, Conv, [256, 3, 2]] # 23 Downsample P2
  # Need to ensure channel match for BiFPN. 
  # Layer 23 is 256. Layer 18 (P3_out) is 512.
  # We should up-project P2_down or down-project P3_out? 
  # Standard BiFPN: fuse same scale.
  # Let's project P2_down to 512.
  - [-1, 1, Conv, [512, 1, 1]] # 24 Project 256 -> 512
  - [[-1, 18], 1, BiFPN_Add2, [512, 512]] # 25 Fuse P2_up + P3_out (Layer 18)
  - [-1, 2, A2C2f, [512, False, -1]] # 26 (P3_final_out)

  # Bottom-up P3 -> P4
  - [-1, 1, Conv, [512, 3, 2]] # 27 Downsample P3
  - [[-1, 15], 1, BiFPN_Add2, [512, 512]] # 28 Fuse P3_down + P4_td (Layer 15)
  - [-1, 2, A2C2f, [512, False, -1]] # 29 (P4_final_out)

  # Bottom-up P4 -> P5
  - [-1, 1, Conv, [1024, 3, 2]] # 30 Downsample P4
  - [[-1, 11], 1, BiFPN_Add2, [1024, 1024]] # 31 Fuse P4_down + P5 (Layer 11)
  - [-1, 2, C3k2, [1024, True]] # 32 (P5_final_out)

  - [[22, 26, 29, 32], 1, Detect, [nc]] # Detect(P2, P3, P4, P5) - 4 Heads
